{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import laspy\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import rasterio\n",
    "from rasterio.features import shapes\n",
    "\n",
    "import shapely\n",
    "from shapely.geometry import Polygon, mapping\n",
    "from PIL import Image\n",
    "from matplotlib.path import Path as plt_path\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv = conv_block(in_c, out_c)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        p = self.pool(x)\n",
    "        return x, p\n",
    "    \n",
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv = conv_block(out_c+out_c, out_c)\n",
    "    \n",
    "    def forward(self, inputs, skip):\n",
    "        x = self.up(inputs)\n",
    "        x = torch.cat([x, skip], axis=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "class ConvUNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #\"\"\" Encoder \"\"\"\n",
    "        self.e1 = encoder_block(1, 64).cuda()\n",
    "        self.e2 = encoder_block(64, 128).cuda()\n",
    "        self.e3 = encoder_block(128, 256).cuda()\n",
    "        self.e4 = encoder_block(256, 512).cuda()\n",
    "        #\"\"\" Bottleneck \"\"\"\n",
    "        self.b = conv_block(512, 1024).cuda()\n",
    "        #\"\"\" Decoder \"\"\"\n",
    "        self.d1 = decoder_block(1024, 512).cuda()\n",
    "        self.d2 = decoder_block(512, 256).cuda()\n",
    "        self.d3 = decoder_block(256, 128).cuda()\n",
    "        self.d4 = decoder_block(128, 64).cuda()\n",
    "        #\"\"\" Classifier \"\"\"\n",
    "        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0).cuda()\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        #\"\"\" Encoder \"\"\"\n",
    "        s1, p1 = self.e1(inputs)\n",
    "        s2, p2 = self.e2(p1)\n",
    "        s3, p3 = self.e3(p2)\n",
    "        s4, p4 = self.e4(p3)\n",
    "\n",
    "        #\"\"\" Bottleneck \"\"\"\n",
    "        b = self.b(p4)\n",
    "\n",
    "        #\"\"\" Decoder \"\"\"\n",
    "        d1 = self.d1(b, s4)\n",
    "        d2 = self.d2(d1, s3)\n",
    "        d3 = self.d3(d2, s2)\n",
    "        d4 = self.d4(d3, s1)\n",
    "\n",
    "        #\"\"\" Classifier \"\"\"\n",
    "        outputs = self.outputs(d4)\n",
    "        return outputs\n",
    "\n",
    "class PolygonCNN(object):\n",
    "    def __init__(self, path_to_data, path_to_model, image_size, meters_around_line, threshold, cc_area, simplify_tolerance):\n",
    "        self.path_to_data = path_to_data\n",
    "        self.model = ConvUNet()\n",
    "        self.model.load_state_dict(torch.load(path_to_model))\n",
    "        self.image_size = image_size\n",
    "        self.threshold = threshold\n",
    "        self.meters_around_line = meters_around_line\n",
    "        self.cc_area = cc_area\n",
    "        self.simplify_tolerance = simplify_tolerance\n",
    "        self.transform_img_gray = transforms.Compose([transforms.Resize((image_size,image_size)), transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "    def __call__(self, filename):\n",
    "        lines_image = self.ImageProcessing(filename)\n",
    "        reg_polygons, multi_polygons, bbox_reg_polygon, bbox_multi_polygons = self.Polygonize(lines_image)\n",
    "        point_cloud = laspy.read(self.path_to_data+'/LazFilesWithHeightParam/'+filename+'_hag_nn.laz', laz_backend=laspy.compression.LazBackend.LazrsParallel)\n",
    "        indexes_needed = self.FilterPolygons(reg_polygons, multi_polygons, bbox_reg_polygon, bbox_multi_polygons, point_cloud, lines_image)\n",
    "        new_las = self.Predictions(indexes_needed, point_cloud)\n",
    "        return new_las\n",
    "    \n",
    "    def BBTouchingEdge(self, image_shape, bb, epsilon):\n",
    "        image_width, image_height = image_shape\n",
    "        left, top, width, height = bb[0], bb[1], bb[2], bb[3]\n",
    "        right = left + width\n",
    "        bottom = top + height\n",
    "        distance_to_left = left\n",
    "        distance_to_right = image_width - right\n",
    "        distance_to_top = top\n",
    "        distance_to_bottom = image_height - bottom\n",
    "\n",
    "        if distance_to_left > epsilon and distance_to_right > epsilon and distance_to_top > epsilon and distance_to_bottom > epsilon:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def ImageProcessing(self, filename):\n",
    "        # Load Image\n",
    "        image = cv2.imread(self.path_to_data+'/ImagesGroundRemovedLarge/'+filename+'_max.tif', cv2.IMREAD_UNCHANGED)\n",
    "        image = np.where(image >= 0, image, 0)\n",
    "        image = image/np.max(image)\n",
    "        image = (image*255).astype(np.uint8)\n",
    "\n",
    "        # Create pil image\n",
    "        pil_image = Image.fromarray(image)\n",
    "\n",
    "        # Resize Image, Transform to tensor, and Normalize\n",
    "        tensor_image = self.transform_img_gray(pil_image)\n",
    "        x_pixels, y_pixels = tensor_image[0].shape\n",
    "\n",
    "        # Apply model\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = torch.squeeze(self.model(tensor_image.unsqueeze(0).cuda())).detach().cpu()\n",
    "            #outputs = torch.round(torch.sigmoid(outputs)) # Predict either 0 or 1.\n",
    "            outputs = (torch.sigmoid(outputs) > self.threshold).float()\n",
    "        \n",
    "        fig, (ax0, ax1, ax2, ax3) = plt.subplots(1, 4, figsize=(11,11))\n",
    "        ax0.imshow(image, cmap='gray')\n",
    "        ax0.set_title('Original Image', size=8)\n",
    "        \n",
    "        lines_image = outputs.numpy()\n",
    "        ax1.imshow(lines_image, cmap='gray')\n",
    "        ax1.set_title('Segmented Image', size=8)\n",
    "\n",
    "        # Get pixels per meter to create a cirkular kernel size of size \"meters_around_line\"\n",
    "        x_pixels, y_pixels = x_pixels/1000, y_pixels/1000\n",
    "        kernel_size = int(self.meters_around_line*np.ceil(x_pixels))\n",
    "        circular_kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "        # Create a cirkular kernel using (image, center_coordinates, radius, color, thickness)\n",
    "        cv2.circle(circular_kernel, (int(kernel_size/2), int(kernel_size/2)), int(kernel_size/2), 255, -1)\n",
    "        # Apply dilation using the cirkular kernel\n",
    "        lines_image = cv2.dilate(lines_image, circular_kernel, iterations=1)\n",
    "        \n",
    "        ax2.imshow(lines_image, cmap='gray')\n",
    "        ax2.set_title('~'+str(self.meters_around_line)+' Meters\\nDilation', size=8)\n",
    "\n",
    "        # Must be image type for connected components\n",
    "        lines_image = (lines_image * 255).astype(np.uint8)\n",
    "        (_, label_ids, bounding_box, _) = cv2.connectedComponentsWithStats(lines_image)\n",
    "        for i in range(len(bounding_box)):\n",
    "            # Must be 10 Pixels from the edge of the image\n",
    "            if not self.BBTouchingEdge(image.shape, bounding_box[i], 10):\n",
    "                area = bounding_box[i][cv2.CC_STAT_AREA]\n",
    "                if area < cc_area:\n",
    "                    lines_image[label_ids == i] = 0\n",
    "        \n",
    "        ax3.imshow(lines_image, cmap='gray')\n",
    "        ax3.set_title('Prediction\\nConnected Components', size=8)\n",
    "\n",
    "        ax0.axis('off')\n",
    "        ax1.axis('off')\n",
    "        ax2.axis('off')\n",
    "        ax3.axis('off')\n",
    "        plt.savefig('images_4096_rotation_dial/'+filename+'.png', dpi = 200, bbox_inches = 'tight')\n",
    "        return lines_image\n",
    "    \n",
    "\n",
    "    def Polygonize(self, lines_image):\n",
    "\n",
    "        # Create Polygons and Multi Polygons\n",
    "        mask = (lines_image == 255)\n",
    "        output = rasterio.features.shapes(lines_image, mask=mask, connectivity=4)\n",
    "        output_list = list(output)\n",
    "\n",
    "        # Seperate the Multipolygons and Polygons\n",
    "        all_polygons = []\n",
    "        all_multi_polygons =[]\n",
    "        #ipdb.set_trace()\n",
    "\n",
    "        for multi_polygon in output_list:\n",
    "            found_polygon = multi_polygon[0]['coordinates']\n",
    "            # Then its just a Polygon\n",
    "            if len(found_polygon) == 1:\n",
    "                all_polygons.append(Polygon(found_polygon[0]))\n",
    "            # Else its a multipolygon\n",
    "            else:\n",
    "                tmpMulti = []\n",
    "                for p in found_polygon:\n",
    "                    tmpMulti.append(Polygon(p))\n",
    "                all_multi_polygons.append(tmpMulti)\n",
    "\n",
    "        # Remove all low area multipolygons\n",
    "        for i, multi_pol in enumerate(all_multi_polygons):\n",
    "            new_list = [multi_pol[0]]\n",
    "            # No matter what, dont remove the first one\n",
    "            for pol in multi_pol[1:]:\n",
    "                new_list.append(pol)\n",
    "            all_multi_polygons[i] = new_list\n",
    "\n",
    "        simplified_all_polygons = []\n",
    "        simplified_all_multi_polygons =[]\n",
    "        # Simplify all standard polygons\n",
    "        for p in all_polygons:\n",
    "            simplified_all_polygons.append(shapely.simplify(p, tolerance=self.simplify_tolerance, preserve_topology=True))\n",
    "        simplified_all_polygons  = [p for p in simplified_all_polygons if not p.is_empty]\n",
    "\n",
    "        # Simplify all multi polygons\n",
    "        for multi_pol in all_multi_polygons:\n",
    "            tmp = []\n",
    "            for p in multi_pol:\n",
    "                tmp.append(shapely.simplify(p, tolerance=self.simplify_tolerance, preserve_topology=True))\n",
    "            tmp  = [p for p in tmp if not p.is_empty]\n",
    "            simplified_all_multi_polygons.append(tmp)\n",
    "\n",
    "        # Create bounding box polygons\n",
    "        bbox_all_polygon_path = []\n",
    "        tmp = [p.bounds for p in simplified_all_polygons]\n",
    "        for values in tmp:\n",
    "            #values = (minx, miny, maxx, maxy)\n",
    "            x_min = values[0]\n",
    "            x_max = values[2]\n",
    "            y_min = values[1]\n",
    "            y_max = values[3]\n",
    "            bb = [(x_min, y_min), (x_min, y_max), (x_max, y_max), (x_max, y_min)]\n",
    "            bbox_all_polygon_path.append(plt_path(bb))\n",
    "\n",
    "        # Create bounding box for multi polygons\n",
    "        bbox_all_multi_polygons_path = []\n",
    "        for multi_pol in simplified_all_multi_polygons:\n",
    "            tmp = [p.bounds for p in multi_pol]\n",
    "            tmp_multi_pol_boxes = []\n",
    "\n",
    "            for values in tmp:\n",
    "                #values = (minx, miny, maxx, maxy)\n",
    "                x_min = values[0]\n",
    "                x_max = values[2]\n",
    "                y_min = values[1]\n",
    "                y_max = values[3]\n",
    "                bb = [(x_min, y_min), (x_min, y_max), (x_max, y_max), (x_max, y_min)]\n",
    "                tmp_multi_pol_boxes.append(plt_path(bb))\n",
    "            bbox_all_multi_polygons_path.append(tmp_multi_pol_boxes)\n",
    "\n",
    "        # Create plt_path polygons from the simplified shapely polygons\n",
    "        simplified_all_polygons_path = [plt_path(mapping(p)['coordinates'][0]) for p in simplified_all_polygons]\n",
    "        simplified_all_multi_polygons_path = []\n",
    "        for multi_pol in simplified_all_multi_polygons:\n",
    "            tmp = [plt_path(mapping(p)['coordinates'][0]) for p in multi_pol]\n",
    "            simplified_all_multi_polygons_path.append(tmp)\n",
    "\n",
    "        return simplified_all_polygons_path, simplified_all_multi_polygons_path, bbox_all_polygon_path, bbox_all_multi_polygons_path\n",
    "    \n",
    "    def MaxMinNormalize(self, arr):\n",
    "        return (arr - np.min(arr))/(np.max(arr)-np.min(arr))\n",
    "\n",
    "    def CastAllXValuesToImage(self, arr, x_pixels):\n",
    "        return self.MaxMinNormalize(arr)*x_pixels\n",
    "\n",
    "    def CastAllYValuesToImage(self, arr, y_pixels):\n",
    "        return (1-self.MaxMinNormalize(arr))*y_pixels\n",
    "    \n",
    "    def FilterPolygons(self, reg_polygons, multi_polygons, bbox_reg_polygon, bbox_multi_polygons, point_cloud, image):\n",
    "        # Pixels per kilometer\n",
    "        x_pixels, y_pixels = image.shape\n",
    "        x_values = self.CastAllXValuesToImage(point_cloud.X, x_pixels)\n",
    "        y_values = self.CastAllYValuesToImage(point_cloud.Y, y_pixels)\n",
    "\n",
    "        # Format: [(1,1), (3,5), (1,5), ...] with 30 mio samples\n",
    "        list_zipped = np.array(list(zip(x_values, y_values)))\n",
    "\n",
    "        # Generate a bool list to obtain the final indexes from the dataset\n",
    "        indexes_needed = np.zeros(len(x_values), dtype=bool)\n",
    "\n",
    "        # Run through all polygons and check which points are inside the polygon\n",
    "        for i in range(len(reg_polygons)):\n",
    "            # Check if point is inside the bounding box\n",
    "            indexes_inside_box = bbox_reg_polygon[i].contains_points(list_zipped)\n",
    "            indexes_inside_box = np.array([index for index, x in enumerate(indexes_inside_box) if x])\n",
    "\n",
    "            if len(indexes_inside_box) != 0:\n",
    "                # Generate small dataset\n",
    "                tmp = list_zipped[indexes_inside_box]\n",
    "\n",
    "                # Check if any of these points are in the polygon\n",
    "                indexes_inside_polygon = reg_polygons[i].contains_points(tmp)\n",
    "\n",
    "                # Find the indexes from the box that is also inside the polygon\n",
    "                final_indexes = indexes_inside_box[indexes_inside_polygon]\n",
    "\n",
    "                # Update the indexes\n",
    "                indexes_needed[final_indexes] = 1\n",
    "\n",
    "        for i in range(len(multi_polygons)):\n",
    "            tmp_indexes_needed = np.zeros(len(x_values), dtype=bool)\n",
    "            tmp_indexes_not_needed = np.zeros(len(x_values), dtype=bool)\n",
    "\n",
    "            # Get the current bb multipolygon and the current simplified multipolygon\n",
    "            bb_multi_pol = bbox_multi_polygons[i]\n",
    "            simpli_multi_pol = multi_polygons[i]\n",
    "\n",
    "            # Find the indexes that are inside the bounding box of the first element\n",
    "            indexes_inside_box = bb_multi_pol[0].contains_points(list_zipped)\n",
    "            indexes_inside_box = np.array([index for index, x in enumerate(indexes_inside_box) if x])\n",
    "\n",
    "            # Generate smaller dataset\n",
    "            tmp = list_zipped[indexes_inside_box]\n",
    "\n",
    "            # Check if any of these points are in the polygon\n",
    "            indexes_inside_polygon = simpli_multi_pol[0].contains_points(tmp)\n",
    "\n",
    "            # Find the indexes from the box that is also inside the polygon\n",
    "            final_indexes = indexes_inside_box[indexes_inside_polygon]\n",
    "            tmp_indexes_needed[final_indexes] = 1\n",
    "\n",
    "            for j in range(1, len(bb_multi_pol)):\n",
    "\n",
    "                # Get the bounding box of the temp multi polygon\n",
    "                indexes_inside_box = bb_multi_pol[j].contains_points(list_zipped)\n",
    "                indexes_inside_box = np.array([index for index, x in enumerate(indexes_inside_box) if x])\n",
    "                if len(indexes_inside_box) != 0:\n",
    "                    # Generate small dataset\n",
    "                    tmp = list_zipped[indexes_inside_box]\n",
    "\n",
    "                    # Check if any of these points are in the polygon\n",
    "                    indexes_inside_polygon = simpli_multi_pol[j].contains_points(tmp)\n",
    "                    final_indexes = indexes_inside_box[indexes_inside_polygon]\n",
    "\n",
    "                    # Update the indexes\n",
    "                    tmp_indexes_not_needed[final_indexes] = 1\n",
    "\n",
    "                    indexes_needed = indexes_needed | (tmp_indexes_needed & np.invert(tmp_indexes_not_needed))\n",
    "        return indexes_needed\n",
    "    \n",
    "    def Predictions(self, indexes_needed, point_cloud):\n",
    "        new_point_cloud = point_cloud[indexes_needed]\n",
    "        return new_point_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "PUNKTSKY_00004_1km_6105_518\n",
      "4095\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 3.94 GiB total capacity; 184.25 MiB already allocated; 2.85 GiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15709/1083096626.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0moriginal_powerline_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mnew_point_cloud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mnew_powerline_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_point_cloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mpoint_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_point_cloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_point_cloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_point_cloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15709/4229112521.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mlines_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageProcessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mreg_polygons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_polygons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_reg_polygon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_multi_polygons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPolygonize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mpoint_cloud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlaspy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_data\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/LazFilesWithHeightParam/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_hag_nn.laz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlaz_backend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlaspy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLazBackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLazrsParallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15709/4229112521.py\u001b[0m in \u001b[0;36mImageProcessing\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0;31m#outputs = torch.round(torch.sigmoid(outputs)) # Predict either 0 or 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15709/4229112521.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m#\"\"\" Encoder \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0ms3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15709/4229112521.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15709/4229112521.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    451\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 453\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    454\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 3.94 GiB total capacity; 184.25 MiB already allocated; 2.85 GiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "#path_to_data = \"/home/frederik/data/TestData/data/\"\n",
    "path_to_data = \"/home/frederik/Downloads/cnn_test_data\"\n",
    "path_to_model = \"large4096patches128batch256/bestModelStateDict.pth\"\n",
    "\n",
    "image_size = 4096\n",
    "meters_around_line = 12\n",
    "threshold = 0.3\n",
    "cc_area = 10000\n",
    "simplify_tolerance = 8\n",
    "\n",
    "clf = PolygonCNN(path_to_data, path_to_model, image_size, meters_around_line, threshold, cc_area, simplify_tolerance)\n",
    "\n",
    "# names = [\"PUNKTSKY_00005_1km_6134_518\",\n",
    "#         \"PUNKTSKY_00005_1km_6146_468\",\n",
    "#         \"PUNKTSKY_00005_1km_6161_465\",\n",
    "#         \"PUNKTSKY_00005_1km_6162_472\",\n",
    "#         \"PUNKTSKY_00005_1km_6163_472\",\n",
    "#         \"PUNKTSKY_00005_1km_6167_473\",\n",
    "#         \"PUNKTSKY_00005_1km_6167_474\",\n",
    "#         \"PUNKTSKY_00005_1km_6167_475\",\n",
    "#         \"PUNKTSKY_00005_1km_6168_458\",\n",
    "#         \"PUNKTSKY_00005_1km_6204_505\",\n",
    "#         \"PUNKTSKY_00005_1km_6205_513\",\n",
    "#         \"PUNKTSKY_00005_1km_6211_474\",\n",
    "#         \"PUNKTSKY_00005_1km_6219_494\",\n",
    "#         \"PUNKTSKY_00005_1km_6220_495\",\n",
    "#         \"PUNKTSKY_00005_1km_6221_452\"]\n",
    "\n",
    "\n",
    "names = [\"PUNKTSKY_00004_1km_6105_518\",\n",
    "         \"PUNKTSKY_00004_1km_6106_492\",\n",
    "         \"PUNKTSKY_00004_1km_6106_493\",\n",
    "         \"PUNKTSKY_00004_1km_6106_494\",\n",
    "         \"PUNKTSKY_00004_1km_6106_510\"]\n",
    "\n",
    "for name in names:\n",
    "    print(name)\n",
    "    las = laspy.read(path_to_data+'/LazFilesWithHeightParam/'+name+'_hag_nn.laz', laz_backend=laspy.compression.LazBackend.LazrsParallel)\n",
    "    original_powerline_points = np.sum(las.classification == 14)\n",
    "\n",
    "    new_point_cloud = clf(name)\n",
    "    new_powerline_points = np.sum(new_point_cloud.classification == 14)\n",
    "    point_data = np.stack([new_point_cloud.X, new_point_cloud.Y, new_point_cloud.Z], axis=0).transpose((1, 0))\n",
    "\n",
    "    print(\"Powerline Points: \", original_powerline_points)\n",
    "    print(\"Powerline Points after data selection: \", new_powerline_points)\n",
    "\n",
    "    print(\"Lost powerline points: \", original_powerline_points-new_powerline_points)\n",
    "    if original_powerline_points > 0:\n",
    "        print(\"Lost powerline points percent: \", (original_powerline_points-new_powerline_points)/original_powerline_points)\n",
    "    else:\n",
    "        print(\"Lost powerline points: No powerpoint labels in the data\")\n",
    "        \n",
    "    print(\"Total Points Before selection\", len(las))\n",
    "    print(\"Total Points After selection\", len(new_point_cloud))\n",
    "    \n",
    "    print(\"Pct removed points: \", (1 - len(new_point_cloud)/len(las)))\n",
    "\n",
    "#     geom = o3d.geometry.PointCloud()\n",
    "#     geom.points = o3d.utility.Vector3dVector(point_data)\n",
    "#     o3d.visualization.draw_geometries([geom])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
