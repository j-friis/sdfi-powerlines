{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "\n",
    "## import the tools\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import laspy\n",
    "\n",
    "import torch\n",
    "## to find the neighbor points prediction\n",
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## import the model tools\n",
    "from torch_geometric.transforms import Compose\n",
    "from torch_points3d.core.data_transform import MinPoints, XYZFeature, AddFeatsByKeys, GridSampling3D\n",
    "from torch_points3d.core.data_transform.features import AddOnes\n",
    "from torch_points3d.applications.pretrained_api import PretainedRegistry\n",
    "from torch_geometric.data import Batch\n",
    "from torch_points3d.metrics.confusion_matrix import ConfusionMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_neighbors(src_points, candidates, k_neighbors=1):\n",
    "    \"\"\"Find nearest neighbors for all source points from a set of candidate points\"\"\"\n",
    "    tree = KDTree(candidates, leaf_size=20, metric='euclidean')\n",
    "\n",
    "    # Find closest points and distances\n",
    "    distances, indices = tree.query(src_points, k=k_neighbors)\n",
    "\n",
    "    # Transpose to get distances and indices into arrays\n",
    "    distances = distances.transpose()\n",
    "    indices = indices.transpose()\n",
    "\n",
    "    # Get closest indices and distances (i.e. array at index 0)\n",
    "    closest = np.squeeze(indices)\n",
    "    return closest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path: str, data_path: str):\n",
    "    model = torch.load(model_path)\n",
    "    model['run_config']['data']['dataroot'] = data_path\n",
    "    torch.save(model, model_path)\n",
    "    # transformer for non ones\n",
    "    pos_z = [ \"pos_z\" ]\n",
    "    list_add_to_x = [ True ]\n",
    "    delete_feats = [ True ]\n",
    "    first_subsampling = model['run_config'][\"data\"][\"first_subsampling\"]\n",
    "    transform_test = Compose([MinPoints(512),\n",
    "                        XYZFeature(add_x=False, add_y=False, add_z= True),\n",
    "                        AddFeatsByKeys(list_add_to_x=list_add_to_x, feat_names= pos_z,delete_feats=delete_feats),\n",
    "                        GridSampling3D(mode='last', size=first_subsampling, quantize_coords=True)\n",
    "                        ])\n",
    "\n",
    "    # ## transformer for ones\n",
    "    # pos_z = [ \"ones\" ]\n",
    "    # list_add_to_x = [ True ]\n",
    "    # delete_feats = [ True ]\n",
    "    # first_subsampling = model['run_config'][\"data\"][\"first_subsampling\"]\n",
    "    # input_nc_feats = [1]\n",
    "\n",
    "    # transform_test = Compose([MinPoints(512),\n",
    "    #                  AddOnes(),\n",
    "    #                  AddFeatsByKeys(list_add_to_x=list_add_to_x, feat_names= pos_z,delete_feats=delete_feats, input_nc_feats=input_nc_feats),\n",
    "    #                  GridSampling3D(mode='last', size=first_subsampling, quantize_coords=True)\n",
    "    #                  ])\n",
    "    ### ['latest', 'loss_seg', 'acc', 'macc', 'miou']\n",
    "    model_pl = PretainedRegistry.from_file(model_path, weight_name=\"miou\").cuda()\n",
    "    return model_pl, transform_test, model['run_config']['data']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(room_info, model, filename, transform_test, predict_folder):\n",
    "    ## loop for every files\n",
    "    room_coord_mins = room_info['room_coord_min']\n",
    "    room_coord_scales = room_info['room_coord_scale']\n",
    "    files = list(glob.glob(predict_folder + f\"/*{filename}*cloud*pt\"))\n",
    "\n",
    "    pred_data = []\n",
    "\n",
    "    for file in files:\n",
    "        sample = os.path.join(predict_folder, file)\n",
    "        pt_data = torch.load(sample)\n",
    "        room_index = pt_data['room_idx']\n",
    "\n",
    "        room_coord_scale = room_coord_scales[room_index]\n",
    "        pos_ = pt_data['points']\n",
    "        point_in_original_las = pos_ * room_coord_scale + room_coord_mins[room_index]\n",
    "\n",
    "        data_s = transform_test(Batch(pos=torch.from_numpy(pos_).float()))\n",
    "        data_s.batch = torch.zeros(len(data_s.pos))\n",
    "        data_s.y = torch.zeros(data_s.pos.shape[0]).long()\n",
    "        index_to_nearst_neighbor = get_nearest_neighbors(pos_, data_s.pos)\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            model.set_input(data_s, \"cuda\")\n",
    "            model.forward(data_s)\n",
    "        \n",
    "        pre = model.output.cpu().numpy()\n",
    "        m = torch.nn.functional.softmax(torch.tensor(pre), dim=1)\n",
    "        cla_pre = np.argmax(m, axis=1)\n",
    "        pre_ori = np.arange(len(pos_))\n",
    "        if len(pos_) == 1:\n",
    "            pre_ori[0] = cla_pre[0]\n",
    "        else:\n",
    "            for i in pre_ori:\n",
    "                pre_ori[i] = cla_pre[index_to_nearst_neighbor[i]]\n",
    "        combine_pre = np.column_stack((point_in_original_las, pre_ori.T))\n",
    "\n",
    "        pred_data.append(combine_pre)\n",
    "\n",
    "    pred_data = np.array([item for sublist in pred_data for item in sublist])\n",
    "\n",
    "    return pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(pred_data, model_las, whole_las):\n",
    "    ## read original las file\n",
    "\n",
    "    powerline_pts = pred_data[np.where(pred_data[:,3] == 1)].copy()\n",
    "    powerline_pts_coord = powerline_pts[:,:-1].astype(np.int32) \n",
    "\n",
    "    model_las_point_data = np.stack([model_las.X, model_las.Y, model_las.Z], axis=0).transpose((1, 0))\n",
    "    model_las_idx = get_nearest_neighbors(powerline_pts_coord, model_las_point_data)\n",
    "    pred = np.zeros(len(model_las_point_data))\n",
    "    model_las_label = model_las.classification \n",
    "    model_las_label = model_las_label==14 \n",
    "    pred[model_las_idx] = 1\n",
    "    pred = np.asarray(pred,dtype=np.int16)\n",
    "    model_las_label = np.asarray(model_las_label,dtype=np.int16)\n",
    "\n",
    "    cfm = ConfusionMatrix()\n",
    "    #Use as count_predicted_batch(true pred)\n",
    "    cfm.count_predicted_batch(model_las_label, pred)\n",
    "    model_las_metric_dict = {}\n",
    "\n",
    "    model_las_metric_dict[\"acc\"] = 100 * cfm.get_overall_accuracy()\n",
    "    model_las_metric_dict[\"macc\"] = 100 * cfm.get_mean_class_accuracy()\n",
    "    model_las_metric_dict[\"miou\"] = 100 * cfm.get_overall_accuracy()\n",
    "    model_las_metric_dict[\"miou_class\"] = {\n",
    "        i: \"{:.2f}\".format(100 * v)\n",
    "        for i, v in enumerate(cfm.get_intersection_union_per_class()[0])\n",
    "    }\n",
    "    model_las_metric_dict[\"precision\"] = cfm.get_confusion_matrix()[1][1]/(cfm.get_confusion_matrix()[1][1]+cfm.get_confusion_matrix()[0][1])\n",
    "    model_las_metric_dict[\"recall\"] = cfm.get_confusion_matrix()[1][1]/(cfm.get_confusion_matrix()[1][1]+cfm.get_confusion_matrix()[1][0])\n",
    "\n",
    "\n",
    "    whole_las_point_data = np.stack([whole_las.X, whole_las.Y, whole_las.Z], axis=0).transpose((1, 0))\n",
    "    whole_las_idx = get_nearest_neighbors(powerline_pts_coord, whole_las_point_data)\n",
    "    pred = np.zeros(len(whole_las_point_data))\n",
    "    whole_las_label = whole_las.classification \n",
    "    whole_las_label = whole_las_label==14 \n",
    "    pred[whole_las_idx] = 1\n",
    "    pred = np.asarray(pred,dtype=np.int16)\n",
    "    whole_las_label = np.asarray(whole_las_label,dtype=np.int16)\n",
    "\n",
    "    cfm = ConfusionMatrix()\n",
    "    #Use as count_predicted_batch(true pred)\n",
    "    cfm.count_predicted_batch(whole_las_label, pred)\n",
    "    whole_las_metric_dict = {}\n",
    "\n",
    "    whole_las_metric_dict[\"acc\"] = 100 * cfm.get_overall_accuracy()\n",
    "    whole_las_metric_dict[\"macc\"] = 100 * cfm.get_mean_class_accuracy()\n",
    "    whole_las_metric_dict[\"miou\"] = 100 * cfm.get_overall_accuracy()\n",
    "    whole_las_metric_dict[\"miou_class\"] = {\n",
    "        i: \"{:.2f}\".format(100 * v)\n",
    "        for i, v in enumerate(cfm.get_intersection_union_per_class()[0])\n",
    "    }\n",
    "    whole_las_metric_dict[\"precision\"] = cfm.get_confusion_matrix()[1][1]/(cfm.get_confusion_matrix()[1][1]+cfm.get_confusion_matrix()[0][1])\n",
    "    whole_las_metric_dict[\"recall\"] = cfm.get_confusion_matrix()[1][1]/(cfm.get_confusion_matrix()[1][1]+cfm.get_confusion_matrix()[1][0])\n",
    "\n",
    "    return model_las_metric_dict, whole_las_metric_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "loading processed train split\n",
      "Total of 14594 samples in train set.\n",
      "loading processed val split\n",
      "Total of 815 samples in val set.\n",
      "loading processed test split\n",
      "Total of 1232 samples in test set.\n",
      "False\n",
      "64\n",
      "1\n",
      "343\n",
      "False\n",
      "256\n",
      "64\n",
      "1\n",
      "False\n",
      "64\n",
      "64\n",
      "1\n",
      "False\n",
      "64\n",
      "64\n",
      "27\n",
      "False\n",
      "256\n",
      "64\n",
      "1\n",
      "False\n",
      "64\n",
      "256\n",
      "1\n",
      "False\n",
      "64\n",
      "64\n",
      "27\n",
      "False\n",
      "256\n",
      "64\n",
      "1\n",
      "False\n",
      "64\n",
      "256\n",
      "1\n",
      "False\n",
      "64\n",
      "64\n",
      "27\n",
      "False\n",
      "256\n",
      "64\n",
      "1\n",
      "False\n",
      "512\n",
      "256\n",
      "1\n",
      "False\n",
      "128\n",
      "256\n",
      "1\n",
      "False\n",
      "128\n",
      "128\n",
      "8\n",
      "False\n",
      "128\n",
      "128\n",
      "27\n",
      "False\n",
      "512\n",
      "128\n",
      "1\n",
      "False\n",
      "128\n",
      "512\n",
      "1\n",
      "False\n",
      "128\n",
      "128\n",
      "27\n",
      "False\n",
      "512\n",
      "128\n",
      "1\n",
      "False\n",
      "128\n",
      "512\n",
      "1\n",
      "False\n",
      "128\n",
      "128\n",
      "27\n",
      "False\n",
      "512\n",
      "128\n",
      "1\n",
      "False\n",
      "128\n",
      "512\n",
      "1\n",
      "False\n",
      "128\n",
      "128\n",
      "27\n",
      "False\n",
      "512\n",
      "128\n",
      "1\n",
      "False\n",
      "1024\n",
      "512\n",
      "1\n",
      "False\n",
      "256\n",
      "512\n",
      "1\n",
      "False\n",
      "256\n",
      "256\n",
      "8\n",
      "False\n",
      "256\n",
      "256\n",
      "27\n",
      "False\n",
      "1024\n",
      "256\n",
      "1\n",
      "False\n",
      "256\n",
      "1024\n",
      "1\n",
      "False\n",
      "256\n",
      "256\n",
      "27\n",
      "False\n",
      "1024\n",
      "256\n",
      "1\n",
      "False\n",
      "256\n",
      "1024\n",
      "1\n",
      "False\n",
      "256\n",
      "256\n",
      "27\n",
      "False\n",
      "1024\n",
      "256\n",
      "1\n",
      "False\n",
      "256\n",
      "1024\n",
      "1\n",
      "False\n",
      "256\n",
      "256\n",
      "27\n",
      "False\n",
      "1024\n",
      "256\n",
      "1\n",
      "False\n",
      "256\n",
      "1024\n",
      "1\n",
      "False\n",
      "256\n",
      "256\n",
      "27\n",
      "False\n",
      "1024\n",
      "256\n",
      "1\n",
      "False\n",
      "256\n",
      "1024\n",
      "1\n",
      "False\n",
      "256\n",
      "256\n",
      "27\n",
      "False\n",
      "1024\n",
      "256\n",
      "1\n",
      "False\n",
      "2048\n",
      "1024\n",
      "1\n",
      "False\n",
      "512\n",
      "1024\n",
      "1\n",
      "False\n",
      "512\n",
      "512\n",
      "8\n",
      "False\n",
      "512\n",
      "512\n",
      "27\n",
      "False\n",
      "2048\n",
      "512\n",
      "1\n",
      "False\n",
      "512\n",
      "2048\n",
      "1\n",
      "False\n",
      "512\n",
      "512\n",
      "27\n",
      "False\n",
      "2048\n",
      "512\n",
      "1\n",
      "False\n",
      "512\n",
      "2048\n",
      "1\n",
      "False\n",
      "512\n",
      "512\n",
      "27\n",
      "False\n",
      "2048\n",
      "512\n",
      "1\n",
      "True\n",
      "1024\n",
      "2048\n",
      "8\n",
      "False\n",
      "1024\n",
      "2048\n",
      "1\n",
      "False\n",
      "256\n",
      "2048\n",
      "1\n",
      "False\n",
      "256\n",
      "256\n",
      "27\n",
      "False\n",
      "1024\n",
      "256\n",
      "1\n",
      "False\n",
      "256\n",
      "1024\n",
      "1\n",
      "False\n",
      "256\n",
      "256\n",
      "27\n",
      "False\n",
      "1024\n",
      "256\n",
      "1\n",
      "False\n",
      "256\n",
      "1024\n",
      "1\n",
      "False\n",
      "256\n",
      "256\n",
      "27\n",
      "False\n",
      "1024\n",
      "256\n",
      "1\n",
      "False\n",
      "256\n",
      "1024\n",
      "1\n",
      "False\n",
      "256\n",
      "256\n",
      "27\n",
      "False\n",
      "1024\n",
      "256\n",
      "1\n",
      "False\n",
      "256\n",
      "1024\n",
      "1\n",
      "False\n",
      "256\n",
      "256\n",
      "27\n",
      "False\n",
      "1024\n",
      "256\n",
      "1\n",
      "False\n",
      "256\n",
      "1024\n",
      "1\n",
      "False\n",
      "256\n",
      "256\n",
      "27\n",
      "False\n",
      "1024\n",
      "256\n",
      "1\n",
      "True\n",
      "512\n",
      "1024\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2023-05-13 19:33:07,104 - model_checkpoint - Available weights : ['latest', 'loss_seg', 'acc', 'macc', 'miou']\n",
      "INFO - 2023-05-13 19:33:07,105 - model_checkpoint - Model loaded from SEUNet50.pt:best_miou.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "512\n",
      "1024\n",
      "1\n",
      "False\n",
      "128\n",
      "1024\n",
      "1\n",
      "False\n",
      "128\n",
      "128\n",
      "27\n",
      "False\n",
      "512\n",
      "128\n",
      "1\n",
      "False\n",
      "128\n",
      "512\n",
      "1\n",
      "False\n",
      "128\n",
      "128\n",
      "27\n",
      "False\n",
      "512\n",
      "128\n",
      "1\n",
      "False\n",
      "128\n",
      "512\n",
      "1\n",
      "False\n",
      "128\n",
      "128\n",
      "27\n",
      "False\n",
      "512\n",
      "128\n",
      "1\n",
      "False\n",
      "128\n",
      "512\n",
      "1\n",
      "False\n",
      "128\n",
      "128\n",
      "27\n",
      "False\n",
      "512\n",
      "128\n",
      "1\n",
      "True\n",
      "256\n",
      "512\n",
      "8\n",
      "False\n",
      "256\n",
      "512\n",
      "1\n",
      "False\n",
      "64\n",
      "512\n",
      "1\n",
      "False\n",
      "64\n",
      "64\n",
      "27\n",
      "False\n",
      "256\n",
      "64\n",
      "1\n",
      "False\n",
      "64\n",
      "256\n",
      "1\n",
      "False\n",
      "64\n",
      "64\n",
      "27\n",
      "False\n",
      "256\n",
      "64\n",
      "1\n",
      "False\n",
      "64\n",
      "256\n",
      "1\n",
      "False\n",
      "64\n",
      "64\n",
      "27\n",
      "False\n",
      "256\n",
      "64\n",
      "1\n",
      "True\n",
      "128\n",
      "256\n",
      "8\n",
      "False\n",
      "256\n",
      "192\n",
      "1\n",
      "False\n",
      "64\n",
      "192\n",
      "1\n",
      "False\n",
      "64\n",
      "64\n",
      "27\n",
      "False\n",
      "256\n",
      "64\n",
      "1\n",
      "False\n",
      "2\n",
      "256\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2023-05-13 19:33:07,291 - bn_schedulers - Setting batchnorm momentum at 0.1\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/jf/data\"\n",
    "raw_data_path = \"/home/jf/data/denmark/raw/\"\n",
    "model_path = \"/home/jf/Documents/msc/torch-3dpoints-powerline/outputs/2023-05-07/13-32-19/SEUNet50.pt\"\n",
    "\n",
    "model, transform_test, config = load_model(model_path, data_path)\n",
    "\n",
    "## load transform pt pre\n",
    "processed_folder_name = config[\"processed_folder\"] \n",
    "data_root_path = os.path.join(config['dataroot'] , \"denmark\")\n",
    "processed_data_root_path = os.path.join(data_root_path, processed_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predecting on PUNKTSKY_00005_1km_6219_494\n",
      "4095\n",
      "4095\n"
     ]
    }
   ],
   "source": [
    "splits = [\"test\", \"val\", \"train\"]\n",
    "metric_dict = {}\n",
    "for split in splits:\n",
    "    if split == \"train\":\n",
    "        overlap = config[\"train_overlap\"]\n",
    "    if split == \"val\":\n",
    "        overlap = 0\n",
    "    if split == \"test\":\n",
    "        overlap = 0\n",
    "    predict_folder_name = f\"{split}_{overlap}_({config['block_size_x']}, {config['block_size_y']})\"\n",
    "    predict_folder = os.path.join(processed_data_root_path, predict_folder_name)\n",
    "    pre_trans_path = os.path.join(predict_folder, \"stats.pt\")\n",
    "    room_info = torch.load(pre_trans_path)\n",
    "    \n",
    "    files = room_info['room_names']\n",
    "    for filename in files:\n",
    "        print(f\"Predecting on {filename}\")\n",
    "        #the unprocessed file\n",
    "        raw_file_path = os.path.join(raw_data_path,split,filename+\".laz\")\n",
    "        raw_file = laspy.read(raw_file_path, laz_backend=laspy.compression.LazBackend.LazrsParallel)\n",
    "        #the file that the models sees\n",
    "        model_file_path = os.path.join(raw_data_path,split,\"NewLaz\",filename+\".laz\")\n",
    "        model_file = laspy.read(model_file_path, laz_backend=laspy.compression.LazBackend.LazrsParallel)\n",
    "\n",
    "        pred_data = predict(room_info, model, filename, transform_test, predict_folder)\n",
    "        model_las_metric_dict, whole_las_metric_dict = get_metrics(pred_data, model_file,raw_file)\n",
    "        metric_dict[filename] = {\"model\":model_las_metric_dict, \"whole\":whole_las_metric_dict}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"PUNKTSKY_00005_1km_6219_494\": {\n",
      "        \"model\": {\n",
      "            \"acc\": 99.69709392104919,\n",
      "            \"macc\": 70.8878601760246,\n",
      "            \"miou\": 99.69709392104919,\n",
      "            \"miou_class\": {\n",
      "                \"0\": \"99.70\",\n",
      "                \"1\": \"36.75\"\n",
      "            },\n",
      "            \"precision\": 0.7516634050880626,\n",
      "            \"recall\": 0.4183412296465719\n",
      "        },\n",
      "        \"whole\": {\n",
      "            \"acc\": 99.93284608005565,\n",
      "            \"macc\": 70.91060880849615,\n",
      "            \"miou\": 99.93284608005565,\n",
      "            \"miou_class\": {\n",
      "                \"0\": \"99.93\",\n",
      "                \"1\": \"36.75\"\n",
      "            },\n",
      "            \"precision\": 0.7516634050880626,\n",
      "            \"recall\": 0.4183412296465719\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(metric_dict,sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2bfe5fc19ee440272b50e27189dca9d766ee16bd940e6c96fe401988e2293299"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
